#-------------------
#--kafka连接配置
#-------------------
#kafka-zk连接
zookeeper.connect=192.168.199.44:2181
#zookeeper.connect=192.168.99.72:2181
#当不同group中，如果consumer第一次启动时候，在zookeeper中没有初始的offset（读取的offset，不是logfile 的offset），或者offset过大，那么设置
#smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest 
auto.offset.reset=smallest
#zk连接超时时间
zookeeper.session.timeout.ms=5000
#
zookeeper.sync.time.ms=2000
#自动提交时，时间间隔
auto.commit.interval.ms=4000
#kafka接收数据程序一次性处理数量
num = 1000
#serializer.class为消息的序列化类
serializer.class=kafka.serializer.StringEncoder
#异步发送
metadata.broker.list=192.168.199.44:9092
#metadata.broker.list=192.168.99.72:9092
#该属性表示你需要在消息被接收到的时候发送ack给发送者。以保证数据不丢失
request.required.acks=-1
#数据平台消费指定group_id
dataplatform_group_id=cassandra
dataplatform_topic_name=TOPIC_CASSANDRA

#"TOPIC_QYDATA_SOURCE"  //测试环境             ;"TOPIC_QYDATA_SOURCE_SPIDER";   //生产环境
topic_send_data=TOPIC_QYDATA_SOURCE
#TOPIC_QYDATA_SEED2
topic_send_seed_status=TOPIC_QYDATA_SEED2
#TOPIC_QYDATA_SEED1   格式:topicname$对应处理程序类名;格式:topicname$对应处理程序类名
topic_receive_seed=TOPIC_QYDATA_SEED1$com.heetian.spider.utils.ReciveSeedProcess
#-------------------
#--hazelcast配置
#-------------------
#场所有效时间时间--minute
place_timeout_minute=15
#设备在线有效时间--minute
device_timeout_minute=15
#定时更新在线设备周期--minute
device_period_minute=15
#定时更新设备-场所信息任务周期
device_place_period_minute=15
#采集mac有效时间，超时认为下线。
mac_timeout_minute=5
#--告警信息推送到kafka的topic
sendAlertTopic=alert
#-------------------
#--hazelcast配置-end
#-------------------